#!/usr/bin/env python3
"""
æ™ºèƒ½æ–‡ä»¶æ•´ç†å·¥å…· v3.0

åŠŸèƒ½ï¼š
1. å¤šæ–‡ä»¶å¤¹æ•´ç†ï¼ˆä¸‹è½½ã€æ–‡ç¨¿ã€æ¡Œé¢ â†’ é›†ä¸­åˆ°æ–‡ç¨¿æ–‡ä»¶å¤¹ï¼‰
2. æŒ‰æ–‡ä»¶ç±»å‹è‡ªåŠ¨åˆ†ç±»
3. æ™ºèƒ½åŒ–åˆ†ç±»ï¼ˆåŸºäºæ–‡ä»¶åè¯­ä¹‰è¯†åˆ«è®ºæ–‡ã€å‘ç¥¨ã€åˆåŒç­‰ï¼‰
4. æŒ‰æ—¥æœŸå½’æ¡£ï¼ˆæ–‡æ¡£/2026-01/ï¼‰
5. ç›‘æ§æ¨¡å¼ï¼ˆå®æ—¶è‡ªåŠ¨æ•´ç†æ–°æ–‡ä»¶ï¼‰
6. æ’¤é”€åŠŸèƒ½ï¼ˆæ”¯æŒä¸€é”®è¿˜åŸï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
  é¢„è§ˆæ¨¡å¼ï¼š    python organize_downloads.py
  æ‰§è¡Œæ•´ç†ï¼š    python organize_downloads.py --execute
  ç›‘æ§æ¨¡å¼ï¼š    python organize_downloads.py --watch
  æ’¤é”€æ“ä½œï¼š    python organize_downloads.py --undo
  æŸ¥çœ‹å†å²ï¼š    python organize_downloads.py --history
  å•æ–‡ä»¶å¤¹ï¼š    python organize_downloads.py --path ~/Downloads
"""

import os
import sys
import json
import shutil
import argparse
import re
import time
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Optional, Dict, List, Tuple

try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileMovedEvent
    WATCHDOG_AVAILABLE = True
except ImportError:
    WATCHDOG_AVAILABLE = False
    # å®šä¹‰ç©ºåŸºç±»ä»¥é¿å…è¯­æ³•é”™è¯¯
    class FileSystemEventHandler:
        pass
    Observer = None

# ============ é…ç½® ============

# ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
DOWNLOADS_PATH = Path.home() / "Downloads"

# å¤šæ–‡ä»¶å¤¹æ¨¡å¼ï¼šæºæ–‡ä»¶å¤¹é…ç½®
SOURCE_FOLDERS = {
    "Downloads": {"path": Path.home() / "Downloads", "recursive": True},
    "Documents": {"path": Path.home() / "Documents",  "recursive": False},  # ä»…æ‰«æé¡¶å±‚
}

# é›†ä¸­æ•´ç†çš„ç›®æ ‡æ–‡ä»¶å¤¹
TARGET_ROOT = Path.home() / "Documents"

# å†å²è®°å½•æ–‡ä»¶ï¼ˆé›†ä¸­å­˜å‚¨ï¼‰
HISTORY_FILE = Path.home() / ".config" / "download-organizer" / "organize_history.json"

# æ˜¯å¦æŒ‰æ—¥æœŸå½’æ¡£ï¼ˆTrue: æ–‡æ¡£/2026-01/file.pdf, False: æ–‡æ¡£/file.pdfï¼‰
ARCHIVE_BY_DATE = False

# ============ åˆ†ç±»è§„åˆ™ ============

CATEGORIES = {
    "PDFæ–‡æ¡£": [".pdf"],
    "Wordæ–‡æ¡£": [".doc", ".docx", ".rtf", ".odt"],
    "è¡¨æ ¼": [".xlsx", ".xls"],
    "æ¼”ç¤ºæ–‡ç¨¿": [".pptx", ".ppt"],
    "æ–‡æœ¬æ–‡ä»¶": [".txt"],
    "å›¾ç‰‡": [".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp", ".heic", ".svg", ".tiff"],
    "å®‰è£…åŒ…": [".dmg", ".pkg", ".app", ".exe", ".msi", ".zip", ".rar", ".7z", ".tar", ".gz", ".bz2"],
    "è§†é¢‘": [".mp4", ".mov", ".avi", ".mkv", ".wmv", ".flv"],
    "éŸ³é¢‘": [".mp3", ".wav", ".flac", ".aac", ".m4a"],
    "ä»£ç ": [".py", ".js", ".ts", ".html", ".css", ".json", ".xml", ".yaml", ".yml"],
    "æ•°æ®åˆ†æ": [".do", ".csv", ".dta", ".sav", ".rdata", ".sqlite", ".db"],
}

# å·²æ•´ç†çš„åˆ†ç±»æ–‡ä»¶å¤¹åç§°ï¼ˆç”¨äºè·³è¿‡å·²æ•´ç†çš„æ–‡ä»¶ï¼‰
ORGANIZED_FOLDER_NAMES = set(CATEGORIES.keys()) | {"å…¶ä»–"}

# ============ æ™ºèƒ½åˆ†ç±»è§„åˆ™ï¼ˆåŸºäºæ–‡ä»¶åå…³é”®è¯ï¼‰ ============
# æ ¼å¼: (å…³é”®è¯åˆ—è¡¨, å­åˆ†ç±»å)
# ä¼˜å…ˆçº§ä»ä¸Šåˆ°ä¸‹ï¼ŒåŒ¹é…åˆ°ç¬¬ä¸€ä¸ªå°±åœæ­¢

SMART_RULES = {
    "PDFæ–‡æ¡£": [
        # å­¦æœ¯è®ºæ–‡ç‰¹å¾
        (["è®ºæ–‡", "paper", "research", "study", "journal", "review"], "è®ºæ–‡"),
        (["arxiv", "ieee", "acm", "springer", "elsevier", "s2.0-", "1-s2.0"], "è®ºæ–‡"),
        (["æ‘˜è¦", "abstract", "introduction", "conclusion"], "è®ºæ–‡"),
        # å‘ç¥¨
        (["å‘ç¥¨", "invoice", "receipt", "è´¦å•", "bill"], "å‘ç¥¨"),
        # åˆåŒ
        (["åˆåŒ", "contract", "agreement", "åè®®"], "åˆåŒ"),
        # ç®€å†
        (["ç®€å†", "resume", "cv", "curriculum"], "ç®€å†"),
        # æŠ¥å‘Š
        (["æŠ¥å‘Š", "report", "æ±‡æŠ¥", "æ€»ç»“"], "æŠ¥å‘Š"),
        # æ‰‹å†Œ/æ–‡æ¡£
        (["æ‰‹å†Œ", "manual", "guide", "æ•™ç¨‹", "tutorial"], "æ‰‹å†Œ"),
    ],
    "Wordæ–‡æ¡£": [
        # è®ºæ–‡
        (["è®ºæ–‡", "paper", "research", "thesis"], "è®ºæ–‡"),
        # åˆåŒ
        (["åˆåŒ", "contract", "agreement", "åè®®"], "åˆåŒ"),
        # ç®€å†
        (["ç®€å†", "resume", "cv", "curriculum"], "ç®€å†"),
        # æŠ¥å‘Š
        (["æŠ¥å‘Š", "report", "æ±‡æŠ¥", "æ€»ç»“"], "æŠ¥å‘Š"),
    ],
    "å›¾ç‰‡": [
        # æˆªå›¾
        (["screenshot", "æˆªå›¾", "å±å¹•", "screen"], "æˆªå›¾"),
        # ç…§ç‰‡
        (["photo", "img_", "dsc_", "dcim", "9b6b"], "ç…§ç‰‡"),
        # è®¾è®¡ç¨¿
        (["design", "è®¾è®¡", "ui", "mockup"], "è®¾è®¡"),
    ],
}

# è¦è·³è¿‡çš„æ–‡ä»¶
SKIP_FILES = {
    ".DS_Store",
    ".localized",
    "organize_downloads.py",
    ".organize_history.json",
}

SKIP_PATTERNS = [
    ".uploading",
    ".download",
    ".crdownload",
    ".part",
    ".tmp",
]

# ============ æ ¸å¿ƒé€»è¾‘ ============

def get_category(filename: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–åŸºç¡€åˆ†ç±»"""
    ext = Path(filename).suffix.lower()
    for category, extensions in CATEGORIES.items():
        if ext in extensions:
            return category
    return "å…¶ä»–"


def get_smart_subcategory(filename: str, category: str) -> Optional[str]:
    """åŸºäºæ–‡ä»¶åå…³é”®è¯è¿›è¡Œæ™ºèƒ½å­åˆ†ç±»"""
    if category not in SMART_RULES:
        return None

    filename_lower = filename.lower()

    for keywords, subcategory in SMART_RULES[category]:
        for keyword in keywords:
            if keyword.lower() in filename_lower:
                return subcategory

    return None


def get_date_folder(file_path: Path) -> str:
    """è·å–æ–‡ä»¶çš„æ—¥æœŸæ–‡ä»¶å¤¹åï¼ˆå¦‚ 2026-01ï¼‰"""
    try:
        mtime = file_path.stat().st_mtime
        dt = datetime.fromtimestamp(mtime)
        return dt.strftime("%Y-%m")
    except:
        return datetime.now().strftime("%Y-%m")


def should_skip(filename: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥æ–‡ä»¶"""
    if filename in SKIP_FILES:
        return True
    if filename.startswith("."):
        return True
    for pattern in SKIP_PATTERNS:
        if pattern in filename:
            return True
    return False


def get_unique_path(dest_path: Path) -> Path:
    """å¤„ç†é‡åæ–‡ä»¶ï¼Œè¿”å›å”¯ä¸€è·¯å¾„"""
    if not dest_path.exists():
        return dest_path

    base = dest_path.stem
    ext = dest_path.suffix
    parent = dest_path.parent
    counter = 1

    while True:
        new_name = f"{base}_{counter}{ext}"
        new_path = parent / new_name
        if not new_path.exists():
            return new_path
        counter += 1


def format_size(size: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024:
            return f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"


def build_dest_path(filename: str, file_path: Path, target_root: Path) -> Tuple[Path, str]:
    """è®¡ç®—æ–‡ä»¶çš„ç›®æ ‡è·¯å¾„å’Œæ˜¾ç¤ºåˆ†ç±»å

    Returns:
        (dest_folder, display_category)
    """
    category = get_category(filename)
    subcategory = get_smart_subcategory(filename, category)
    date_folder = get_date_folder(file_path) if ARCHIVE_BY_DATE else None

    if subcategory and date_folder:
        dest_folder = target_root / category / subcategory / date_folder
    elif subcategory:
        dest_folder = target_root / category / subcategory
    elif date_folder:
        dest_folder = target_root / category / date_folder
    else:
        dest_folder = target_root / category

    display_category = f"{category}/{subcategory}" if subcategory else category
    return dest_folder, display_category


def is_in_organized_folder(file_path: Path, target_root: Path) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²åœ¨ç›®æ ‡æ ¹ç›®å½•çš„å·²æ•´ç†å­æ–‡ä»¶å¤¹ä¸­"""
    try:
        rel = file_path.relative_to(target_root)
        if len(rel.parts) > 1 and rel.parts[0] in ORGANIZED_FOLDER_NAMES:
            return True
    except ValueError:
        pass
    return False


# ============ å†å²è®°å½•ç®¡ç† ============

def migrate_history_if_needed():
    """ä»æ—§ä½ç½®è¿ç§»å†å²è®°å½•åˆ°æ–°çš„é›†ä¸­ä½ç½®"""
    old_history = Path.home() / "Downloads" / ".organize_history.json"
    if old_history.exists() and not HISTORY_FILE.exists():
        HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(str(old_history), str(HISTORY_FILE))


def load_history() -> List[Dict]:
    """åŠ è½½ç§»åŠ¨å†å²"""
    if not HISTORY_FILE.exists():
        return []
    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return []


def save_history(history: List[Dict]):
    """ä¿å­˜ç§»åŠ¨å†å²"""
    HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def record_move(source: Path, dest: Path):
    """è®°å½•ä¸€æ¬¡ç§»åŠ¨æ“ä½œ"""
    history = load_history()

    # è·å–æœ€æ–°çš„æ‰¹æ¬¡ID
    batch_id = history[-1]["batch_id"] if history and "batch_id" in history[-1] else 0
    current_batch = history[-1] if history and history[-1].get("batch_id") == batch_id else None

    if current_batch and (datetime.now() - datetime.fromisoformat(current_batch["timestamp"])).seconds < 60:
        # åŒä¸€æ‰¹æ¬¡ï¼ˆ60ç§’å†…ï¼‰
        current_batch["moves"].append({
            "source": str(source),
            "dest": str(dest)
        })
    else:
        # æ–°æ‰¹æ¬¡
        history.append({
            "batch_id": batch_id + 1,
            "timestamp": datetime.now().isoformat(),
            "moves": [{
                "source": str(source),
                "dest": str(dest)
            }]
        })

    save_history(history)


def start_new_batch():
    """å¼€å§‹æ–°çš„æ“ä½œæ‰¹æ¬¡"""
    history = load_history()
    batch_id = history[-1]["batch_id"] + 1 if history else 1
    history.append({
        "batch_id": batch_id,
        "timestamp": datetime.now().isoformat(),
        "moves": []
    })
    save_history(history)
    return batch_id


def add_to_batch(source: Path, dest: Path):
    """æ·»åŠ ç§»åŠ¨è®°å½•åˆ°å½“å‰æ‰¹æ¬¡"""
    history = load_history()
    if history:
        history[-1]["moves"].append({
            "source": str(source),
            "dest": str(dest)
        })
        save_history(history)


# ============ ä¸»è¦åŠŸèƒ½ ============

def calculate_moves(source_folders: Dict, target_root: Path) -> Tuple[Dict, List]:
    """è®¡ç®—éœ€è¦ç§»åŠ¨çš„æ–‡ä»¶

    Args:
        source_folders: æºæ–‡ä»¶å¤¹é…ç½® {"name": {"path": Path, "recursive": bool}}
        target_root: é›†ä¸­æ•´ç†çš„ç›®æ ‡æ ¹ç›®å½•
    """
    stats = defaultdict(list)
    skipped = []

    def process_file(file_path: Path, source_name: str):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        filename = file_path.name

        if should_skip(filename):
            skipped.append(filename)
            return

        # è·³è¿‡å·²åœ¨ç›®æ ‡æ ¹ç›®å½•çš„å·²æ•´ç†å­æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
        if is_in_organized_folder(file_path, target_root):
            return

        # ä½¿ç”¨å…±äº«è¾…åŠ©å‡½æ•°è®¡ç®—ç›®æ ‡è·¯å¾„
        dest_folder, display_category = build_dest_path(filename, file_path, target_root)
        dest_path = dest_folder / filename

        # å¦‚æœæ–‡ä»¶å·²ç»åœ¨æ­£ç¡®ä½ç½®ï¼Œè·³è¿‡
        if file_path.parent == dest_folder:
            return

        dest_path = get_unique_path(dest_path)

        try:
            file_size = file_path.stat().st_size
        except OSError:
            return

        date_folder = get_date_folder(file_path) if ARCHIVE_BY_DATE else None

        stats[display_category].append({
            "source": file_path,
            "dest": dest_path,
            "size": file_size,
            "date_folder": date_folder,
            "source_folder": source_name,
        })

    def scan_directory(dir_path: Path, source_name: str, recursive: bool, depth: int = 0):
        """æ‰«æç›®å½•"""
        try:
            items = list(dir_path.iterdir())
        except PermissionError:
            return

        for item in items:
            if item.is_file():
                process_file(item, source_name)
            elif item.is_dir() and recursive:
                # è·³è¿‡éšè—æ–‡ä»¶å¤¹å’Œ.appåŒ…
                if item.name.startswith(".") or item.name.endswith(".app"):
                    continue
                # å½“æºæ–‡ä»¶å¤¹å°±æ˜¯ç›®æ ‡æ ¹ç›®å½•æ—¶ï¼Œè·³è¿‡å·²æ•´ç†çš„åˆ†ç±»æ–‡ä»¶å¤¹
                if dir_path == target_root and item.name in ORGANIZED_FOLDER_NAMES:
                    continue
                scan_directory(item, source_name, recursive, depth + 1)

    for source_name, config in source_folders.items():
        source_path = config["path"]
        if not source_path.exists():
            continue
        scan_directory(source_path, source_name, recursive=config["recursive"])

    return stats, skipped


def print_preview(stats: Dict, skipped: List, source_folders: Dict, target_root: Path, dry_run: bool = True):
    """æ‰“å°é¢„è§ˆä¿¡æ¯"""
    print("\n" + "="*60)
    print(f"{'ğŸ“‹ é¢„è§ˆæ¨¡å¼' if dry_run else 'ğŸš€ æ‰§è¡Œæ¨¡å¼'}")
    print(f"ğŸ“‚ ç›®æ ‡æ–‡ä»¶å¤¹: {target_root}")
    print(f"ğŸ“¥ æ‰«ææ¥æº: {', '.join(source_folders.keys())}")
    if ARCHIVE_BY_DATE:
        print(f"ğŸ“… æŒ‰æ—¥æœŸå½’æ¡£å·²å¯ç”¨")
    print("="*60)

    total_files = 0
    total_size = 0

    for category, files in sorted(stats.items()):
        count = len(files)
        size = sum(f["size"] for f in files)
        total_files += count
        total_size += size

        print(f"\nğŸ“ {category}/ ({count}ä¸ªæ–‡ä»¶, {format_size(size)})")

        # æŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
        if ARCHIVE_BY_DATE:
            by_date = defaultdict(list)
            for f in files:
                by_date[f["date_folder"]].append(f)

            for date_folder in sorted(by_date.keys(), reverse=True):
                date_files = by_date[date_folder]
                print(f"   ğŸ“† {date_folder}/ ({len(date_files)}ä¸ª)")
                for f in date_files[:3]:
                    origin = f.get("source_folder", "")
                    print(f"      â””â”€ [{origin}] {f['source'].name}")
                if len(date_files) > 3:
                    print(f"      â””â”€ ... è¿˜æœ‰{len(date_files)-3}ä¸ªæ–‡ä»¶")
        else:
            for f in files[:5]:
                origin = f.get("source_folder", "")
                print(f"   â””â”€ [{origin}] {f['source'].name}")
            if len(files) > 5:
                print(f"   â””â”€ ... è¿˜æœ‰{len(files)-5}ä¸ªæ–‡ä»¶")

    print(f"\n" + "-"*60)
    print(f"æ€»è®¡: {total_files}ä¸ªæ–‡ä»¶, {format_size(total_size)}")

    if skipped:
        print(f"è·³è¿‡: {len(skipped)}ä¸ªæ–‡ä»¶ (éšè—æ–‡ä»¶/æ­£åœ¨ä¸‹è½½)")


def organize_files(source_folders: Dict, target_root: Path, dry_run: bool = True):
    """æ•´ç†å¤šä¸ªæ–‡ä»¶å¤¹çš„æ–‡ä»¶åˆ°é›†ä¸­ç›®æ ‡"""
    # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
    target_root.mkdir(parents=True, exist_ok=True)

    stats, skipped = calculate_moves(source_folders, target_root)
    print_preview(stats, skipped, source_folders, target_root, dry_run)

    if dry_run:
        print(f"\nğŸ’¡ è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œæœªåšä»»ä½•æ›´æ”¹")
        print(f"   æ‰§è¡Œæ•´ç†è¯·è¿è¡Œ: python {Path(__file__).name} --execute")
        print(f"   å¯åŠ¨ç›‘æ§æ¨¡å¼: python {Path(__file__).name} --watch")
        return

    # å¼€å§‹æ–°æ‰¹æ¬¡
    batch_id = start_new_batch()
    print(f"\næ­£åœ¨æ•´ç†æ–‡ä»¶... (æ‰¹æ¬¡ #{batch_id})")

    moved_count = 0
    total_files = sum(len(files) for files in stats.values())

    for category, files in stats.items():
        for f in files:
            try:
                f["dest"].parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(f["source"]), str(f["dest"]))
                add_to_batch(f["source"], f["dest"])
                moved_count += 1
            except Exception as e:
                print(f"   âŒ ç§»åŠ¨å¤±è´¥: {f['source'].name} - {e}")

    print(f"\nâœ… å®Œæˆï¼æˆåŠŸç§»åŠ¨ {moved_count}/{total_files} ä¸ªæ–‡ä»¶")
    print(f"   å¦‚éœ€æ’¤é”€ï¼Œè¿è¡Œ: python {Path(__file__).name} --undo")


def undo_last_batch():
    """æ’¤é”€æœ€åä¸€æ‰¹ç§»åŠ¨æ“ä½œ"""
    history = load_history()

    if not history:
        print("æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")
        return

    # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆæ‰¹æ¬¡
    last_batch = None
    for batch in reversed(history):
        if batch["moves"]:
            last_batch = batch
            break

    if not last_batch:
        print("æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")
        return

    print(f"\næ’¤é”€æ‰¹æ¬¡ #{last_batch['batch_id']} ({last_batch['timestamp']})")
    print(f"å…± {len(last_batch['moves'])} ä¸ªæ–‡ä»¶")
    print("-" * 40)

    restored = 0
    for move in last_batch["moves"]:
        source = Path(move["source"])
        dest = Path(move["dest"])

        if dest.exists():
            try:
                # ç¡®ä¿æºç›®å½•å­˜åœ¨
                source.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(dest), str(source))
                print(f"   âœ… è¿˜åŸ: {source.name}")
                restored += 1
            except Exception as e:
                print(f"   âŒ è¿˜åŸå¤±è´¥: {dest.name} - {e}")
        else:
            print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {dest}")

    # ä»å†å²ä¸­ç§»é™¤è¯¥æ‰¹æ¬¡
    history = [b for b in history if b["batch_id"] != last_batch["batch_id"]]
    save_history(history)

    print(f"\nâœ… å·²è¿˜åŸ {restored}/{len(last_batch['moves'])} ä¸ªæ–‡ä»¶")

    # æ¸…ç†ç›®æ ‡æ–‡ä»¶å¤¹ä¸­çš„ç©ºåˆ†ç±»æ–‡ä»¶å¤¹
    cleanup_empty_folders(TARGET_ROOT)


def cleanup_empty_folders(path: Path, depth: int = 0):
    """æ¸…ç†ç©ºæ–‡ä»¶å¤¹ï¼ˆä»…æ¸…ç†å·²æ•´ç†çš„åˆ†ç±»æ–‡ä»¶å¤¹ï¼Œä¸åˆ é™¤ç”¨æˆ·è‡ªå»ºæ–‡ä»¶å¤¹ï¼‰"""
    try:
        items = list(path.iterdir())
    except PermissionError:
        return

    for folder in items:
        if folder.is_dir() and folder.name not in SKIP_FILES:
            # é¡¶å±‚åªæ¸…ç†åˆ†ç±»æ–‡ä»¶å¤¹
            if depth == 0 and folder.name not in ORGANIZED_FOLDER_NAMES:
                continue
            cleanup_empty_folders(folder, depth + 1)
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºï¼ˆå¿½ç•¥.DS_Storeï¼‰
                contents = [f for f in folder.iterdir() if f.name != ".DS_Store"]
                if not contents:
                    # åˆ é™¤.DS_Storeå’Œæ–‡ä»¶å¤¹
                    for f in folder.iterdir():
                        f.unlink()
                    folder.rmdir()
            except:
                pass


def show_history():
    """æ˜¾ç¤ºç§»åŠ¨å†å²"""
    history = load_history()

    if not history:
        print("æ²¡æœ‰æ“ä½œå†å²")
        return

    print("\nğŸ“œ æ“ä½œå†å²")
    print("=" * 60)

    for batch in reversed(history[-10:]):  # åªæ˜¾ç¤ºæœ€è¿‘10æ‰¹
        timestamp = datetime.fromisoformat(batch["timestamp"]).strftime("%Y-%m-%d %H:%M:%S")
        count = len(batch["moves"])
        print(f"\næ‰¹æ¬¡ #{batch['batch_id']} | {timestamp} | {count}ä¸ªæ–‡ä»¶")

        for move in batch["moves"][:3]:
            source_name = Path(move["source"]).name
            try:
                dest_folder = Path(move["dest"]).parent.relative_to(TARGET_ROOT)
            except ValueError:
                dest_folder = Path(move["dest"]).parent
            print(f"   {source_name} â†’ {dest_folder}/")

        if count > 3:
            print(f"   ... è¿˜æœ‰{count-3}ä¸ªæ–‡ä»¶")


# ============ ç›‘æ§æ¨¡å¼ ============

class FileHandler(FileSystemEventHandler):
    """æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨ï¼ˆæ”¯æŒå¤šæºæ–‡ä»¶å¤¹ â†’ é›†ä¸­ç›®æ ‡ï¼‰"""

    def __init__(self, source_path: Path, target_root: Path, source_name: str, recursive: bool):
        self.source_path = source_path
        self.target_root = target_root
        self.source_name = source_name
        self.recursive = recursive
        self.pending_files = {}  # ç­‰å¾…å¤„ç†çš„æ–‡ä»¶
        self.process_delay = 2  # ç­‰å¾…æ–‡ä»¶ä¸‹è½½å®Œæˆçš„å»¶è¿Ÿï¼ˆç§’ï¼‰

    def on_created(self, event):
        if event.is_directory:
            return
        self._schedule_process(Path(event.src_path))

    def on_moved(self, event):
        if event.is_directory:
            return
        dest_path = Path(event.dest_path)
        self._schedule_process(dest_path)

    def _schedule_process(self, file_path: Path):
        """å»¶è¿Ÿå¤„ç†æ–‡ä»¶ï¼ˆç­‰å¾…ä¸‹è½½å®Œæˆï¼‰"""
        # éé€’å½’æ¨¡å¼ï¼šåªå¤„ç†æºæ–‡ä»¶å¤¹é¡¶å±‚çš„æ–‡ä»¶
        if not self.recursive:
            if file_path.parent != self.source_path:
                return
        else:
            # ç¡®ä¿æ–‡ä»¶åœ¨æºæ–‡ä»¶å¤¹ä¸‹
            try:
                file_path.relative_to(self.source_path)
            except ValueError:
                return

        # è·³è¿‡å·²åœ¨ç›®æ ‡æ ¹ç›®å½•çš„å·²æ•´ç†å­æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
        if is_in_organized_folder(file_path, self.target_root):
            return

        filename = file_path.name

        if should_skip(filename):
            return

        # è®°å½•æ–‡ä»¶ï¼Œç¨åå¤„ç†
        self.pending_files[str(file_path)] = time.time()

    def process_pending(self):
        """å¤„ç†ç­‰å¾…ä¸­çš„æ–‡ä»¶"""
        now = time.time()
        to_remove = []

        for file_path_str, timestamp in list(self.pending_files.items()):
            if now - timestamp < self.process_delay:
                continue

            file_path = Path(file_path_str)
            to_remove.append(file_path_str)

            if not file_path.exists():
                continue

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿˜åœ¨è¢«å†™å…¥
            try:
                size1 = file_path.stat().st_size
                time.sleep(0.5)
                size2 = file_path.stat().st_size
                if size1 != size2:
                    # æ–‡ä»¶è¿˜åœ¨ä¸‹è½½ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
                    self.pending_files[file_path_str] = now
                    to_remove.remove(file_path_str)
                    continue
            except:
                continue

            # å¤„ç†æ–‡ä»¶
            self._process_file(file_path)

        for path in to_remove:
            self.pending_files.pop(path, None)

    def _process_file(self, file_path: Path):
        """æ•´ç†å•ä¸ªæ–‡ä»¶åˆ°é›†ä¸­ç›®æ ‡"""
        filename = file_path.name

        # ä½¿ç”¨å…±äº«è¾…åŠ©å‡½æ•°è®¡ç®—ç›®æ ‡è·¯å¾„
        dest_folder, display_category = build_dest_path(filename, file_path, self.target_root)
        date_folder = get_date_folder(file_path) if ARCHIVE_BY_DATE else None

        dest_path = dest_folder / filename

        # å¦‚æœå·²åœ¨æ­£ç¡®ä½ç½®ï¼Œè·³è¿‡
        if file_path.parent == dest_folder:
            return

        dest_path = get_unique_path(dest_path)

        try:
            dest_folder.mkdir(parents=True, exist_ok=True)
            shutil.move(str(file_path), str(dest_path))
            record_move(file_path, dest_path)

            print(f"   âœ… [{self.source_name}] {filename} â†’ {display_category}/{date_folder or ''}")
        except Exception as e:
            print(f"   âŒ ç§»åŠ¨å¤±è´¥: {filename} - {e}")


def watch_folders(source_folders: Dict, target_root: Path):
    """ç›‘æ§å¤šä¸ªæ–‡ä»¶å¤¹"""
    if not WATCHDOG_AVAILABLE:
        print("âŒ ç›‘æ§æ¨¡å¼éœ€è¦å®‰è£… watchdog åº“")
        print("   è¿è¡Œ: pip install watchdog")
        return

    print("\n" + "="*60)
    print("ğŸ‘€ ç›‘æ§æ¨¡å¼å·²å¯åŠ¨")
    print("="*60)
    print(f"ğŸ“‚ ç›®æ ‡æ–‡ä»¶å¤¹: {target_root}")
    for name, cfg in source_folders.items():
        recursive_str = "é€’å½’" if cfg["recursive"] else "ä»…é¡¶å±‚"
        print(f"   ğŸ“¥ {name}: {cfg['path']} ({recursive_str})")
    print(f"æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
    print("-"*60 + "\n")

    handlers = []
    observer = Observer()

    for name, cfg in source_folders.items():
        source_path = cfg["path"]
        if not source_path.exists():
            print(f"   âš ï¸ è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡: {source_path}")
            continue

        handler = FileHandler(
            source_path=source_path,
            target_root=target_root,
            source_name=name,
            recursive=cfg["recursive"],
        )
        handlers.append(handler)

        # Documentsï¼ˆéé€’å½’æºä¸”æ˜¯ç›®æ ‡ï¼‰ï¼šç›‘æ§è®¾ä¸ºéé€’å½’ï¼Œé˜²æ­¢åé¦ˆå¾ªç¯
        watch_recursive = cfg["recursive"]
        if source_path == target_root:
            watch_recursive = False

        observer.schedule(handler, str(source_path), recursive=watch_recursive)

    observer.start()

    try:
        while True:
            time.sleep(1)
            for handler in handlers:
                handler.process_pending()
    except KeyboardInterrupt:
        print("\n\nåœæ­¢ç›‘æ§...")
        observer.stop()

    observer.join()
    print("âœ… ç›‘æ§å·²åœæ­¢")


# ============ ä¸»å…¥å£ ============

def main():
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½æ–‡ä»¶æ•´ç†å·¥å…· v3.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python organize_downloads.py           # é¢„è§ˆæ¨¡å¼ï¼ˆæ•´ç†ä¸‹è½½+æ–‡ç¨¿+æ¡Œé¢ â†’ æ–‡ç¨¿ï¼‰
  python organize_downloads.py -e        # æ‰§è¡Œæ•´ç†
  python organize_downloads.py -w        # ç›‘æ§æ¨¡å¼
  python organize_downloads.py --undo    # æ’¤é”€ä¸Šæ¬¡æ“ä½œ
  python organize_downloads.py --no-date # ä¸æŒ‰æ—¥æœŸå½’æ¡£
  python organize_downloads.py -p ~/Downloads  # ä»…æ•´ç†ä¸‹è½½æ–‡ä»¶å¤¹ï¼ˆå‘åå…¼å®¹ï¼‰
        """
    )
    parser.add_argument(
        "--execute", "-e",
        action="store_true",
        help="æ‰§è¡Œæ¨¡å¼ï¼Œå®é™…ç§»åŠ¨æ–‡ä»¶"
    )
    parser.add_argument(
        "--watch", "-w",
        action="store_true",
        help="ç›‘æ§æ¨¡å¼ï¼Œå®æ—¶æ•´ç†æ–°æ–‡ä»¶"
    )
    parser.add_argument(
        "--undo", "-u",
        action="store_true",
        help="æ’¤é”€ä¸Šä¸€æ‰¹ç§»åŠ¨æ“ä½œ"
    )
    parser.add_argument(
        "--history",
        action="store_true",
        help="æ˜¾ç¤ºæ“ä½œå†å²"
    )
    parser.add_argument(
        "--no-date",
        action="store_true",
        help="ä¸æŒ‰æ—¥æœŸå½’æ¡£"
    )
    parser.add_argument(
        "--path", "-p",
        default=None,
        help="å•æ–‡ä»¶å¤¹æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰ï¼ŒæŒ‡å®šå•ä¸ªæ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--target", "-t",
        default=None,
        help=f"è‡ªå®šä¹‰ç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆé»˜è®¤ {TARGET_ROOT}ï¼‰"
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥æœŸå½’æ¡£é€‰é¡¹
    global ARCHIVE_BY_DATE
    if args.no_date:
        ARCHIVE_BY_DATE = False

    # è¿ç§»æ—§å†å²è®°å½•
    migrate_history_if_needed()

    # ç¡®å®šç›®æ ‡æ–‡ä»¶å¤¹
    target_root = Path(args.target).expanduser() if args.target else TARGET_ROOT

    if args.undo:
        undo_last_batch()
    elif args.history:
        show_history()
    elif args.path:
        # å•æ–‡ä»¶å¤¹æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        single_path = Path(args.path).expanduser()
        single_source = {"Custom": {"path": single_path, "recursive": True}}
        # å•æ–‡ä»¶å¤¹æ¨¡å¼ä¸‹ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®š --targetï¼Œåˆ™ç›®æ ‡å°±æ˜¯æºæ–‡ä»¶å¤¹æœ¬èº«
        single_target = target_root if args.target else single_path
        if args.watch:
            watch_folders(single_source, single_target)
        else:
            organize_files(single_source, single_target, dry_run=not args.execute)
    else:
        # å¤šæ–‡ä»¶å¤¹æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        if args.watch:
            watch_folders(SOURCE_FOLDERS, target_root)
        else:
            organize_files(SOURCE_FOLDERS, target_root, dry_run=not args.execute)


if __name__ == "__main__":
    main()
