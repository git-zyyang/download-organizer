#!/usr/bin/env python3
"""
ä¸‹è½½æ–‡ä»¶å¤¹æ™ºèƒ½æ•´ç†å·¥å…· v2.0

åŠŸèƒ½ï¼š
1. æŒ‰æ–‡ä»¶ç±»å‹è‡ªåŠ¨åˆ†ç±»
2. æ™ºèƒ½åŒ–åˆ†ç±»ï¼ˆåŸºäºæ–‡ä»¶åè¯­ä¹‰è¯†åˆ«è®ºæ–‡ã€å‘ç¥¨ã€åˆåŒç­‰ï¼‰
3. æŒ‰æ—¥æœŸå½’æ¡£ï¼ˆæ–‡æ¡£/2026-01/ï¼‰
4. ç›‘æ§æ¨¡å¼ï¼ˆå®æ—¶è‡ªåŠ¨æ•´ç†æ–°ä¸‹è½½çš„æ–‡ä»¶ï¼‰
5. æ’¤é”€åŠŸèƒ½ï¼ˆæ”¯æŒä¸€é”®è¿˜åŸï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
  é¢„è§ˆæ¨¡å¼ï¼š    python organize_downloads.py
  æ‰§è¡Œæ•´ç†ï¼š    python organize_downloads.py --execute
  ç›‘æ§æ¨¡å¼ï¼š    python organize_downloads.py --watch
  æ’¤é”€æ“ä½œï¼š    python organize_downloads.py --undo
  æŸ¥çœ‹å†å²ï¼š    python organize_downloads.py --history
"""

import os
import sys
import json
import shutil
import argparse
import re
import time
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Optional, Dict, List, Tuple

try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileMovedEvent
    WATCHDOG_AVAILABLE = True
except ImportError:
    WATCHDOG_AVAILABLE = False
    # å®šä¹‰ç©ºåŸºç±»ä»¥é¿å…è¯­æ³•é”™è¯¯
    class FileSystemEventHandler:
        pass
    Observer = None

# ============ é…ç½® ============

# ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„
DOWNLOADS_PATH = Path.home() / "Downloads"

# å†å²è®°å½•æ–‡ä»¶
HISTORY_FILE = DOWNLOADS_PATH / ".organize_history.json"

# æ˜¯å¦æŒ‰æ—¥æœŸå½’æ¡£ï¼ˆTrue: æ–‡æ¡£/2026-01/file.pdf, False: æ–‡æ¡£/file.pdfï¼‰
ARCHIVE_BY_DATE = True

# ============ åˆ†ç±»è§„åˆ™ ============

CATEGORIES = {
    "æ–‡æ¡£": [".pdf", ".doc", ".docx", ".txt", ".rtf", ".odt", ".xlsx", ".xls", ".pptx", ".ppt"],
    "å›¾ç‰‡": [".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp", ".heic", ".svg", ".tiff"],
    "å®‰è£…åŒ…": [".dmg", ".pkg", ".app", ".exe", ".msi", ".zip", ".rar", ".7z", ".tar", ".gz", ".bz2"],
    "è§†é¢‘": [".mp4", ".mov", ".avi", ".mkv", ".wmv", ".flv"],
    "éŸ³é¢‘": [".mp3", ".wav", ".flac", ".aac", ".m4a"],
    "ä»£ç ": [".py", ".js", ".ts", ".html", ".css", ".json", ".xml", ".yaml", ".yml"],
    "æ•°æ®åˆ†æ": [".do", ".csv", ".dta", ".sav", ".rdata", ".sqlite", ".db"],
}

# ============ æ™ºèƒ½åˆ†ç±»è§„åˆ™ï¼ˆåŸºäºæ–‡ä»¶åå…³é”®è¯ï¼‰ ============
# æ ¼å¼: (å…³é”®è¯åˆ—è¡¨, å­åˆ†ç±»å)
# ä¼˜å…ˆçº§ä»ä¸Šåˆ°ä¸‹ï¼ŒåŒ¹é…åˆ°ç¬¬ä¸€ä¸ªå°±åœæ­¢

SMART_RULES = {
    "æ–‡æ¡£": [
        # å­¦æœ¯è®ºæ–‡ç‰¹å¾
        (["è®ºæ–‡", "paper", "research", "study", "journal", "review"], "è®ºæ–‡"),
        (["arxiv", "ieee", "acm", "springer", "elsevier", "s2.0-", "1-s2.0"], "è®ºæ–‡"),
        (["æ‘˜è¦", "abstract", "introduction", "conclusion"], "è®ºæ–‡"),
        # å‘ç¥¨
        (["å‘ç¥¨", "invoice", "receipt", "è´¦å•", "bill"], "å‘ç¥¨"),
        # åˆåŒ
        (["åˆåŒ", "contract", "agreement", "åè®®"], "åˆåŒ"),
        # ç®€å†
        (["ç®€å†", "resume", "cv", "curriculum"], "ç®€å†"),
        # æŠ¥å‘Š
        (["æŠ¥å‘Š", "report", "æ±‡æŠ¥", "æ€»ç»“"], "æŠ¥å‘Š"),
        # æ‰‹å†Œ/æ–‡æ¡£
        (["æ‰‹å†Œ", "manual", "guide", "æ•™ç¨‹", "tutorial"], "æ‰‹å†Œ"),
    ],
    "å›¾ç‰‡": [
        # æˆªå›¾
        (["screenshot", "æˆªå›¾", "å±å¹•", "screen"], "æˆªå›¾"),
        # ç…§ç‰‡
        (["photo", "img_", "dsc_", "dcim", "9b6b"], "ç…§ç‰‡"),
        # è®¾è®¡ç¨¿
        (["design", "è®¾è®¡", "ui", "mockup"], "è®¾è®¡"),
    ],
}

# è¦è·³è¿‡çš„æ–‡ä»¶
SKIP_FILES = {
    ".DS_Store",
    ".localized",
    "organize_downloads.py",
    ".organize_history.json",
}

SKIP_PATTERNS = [
    ".uploading",
    ".download",
    ".crdownload",
    ".part",
    ".tmp",
]

# ============ æ ¸å¿ƒé€»è¾‘ ============

def get_category(filename: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–åŸºç¡€åˆ†ç±»"""
    ext = Path(filename).suffix.lower()
    for category, extensions in CATEGORIES.items():
        if ext in extensions:
            return category
    return "å…¶ä»–"


def get_smart_subcategory(filename: str, category: str) -> Optional[str]:
    """åŸºäºæ–‡ä»¶åå…³é”®è¯è¿›è¡Œæ™ºèƒ½å­åˆ†ç±»"""
    if category not in SMART_RULES:
        return None

    filename_lower = filename.lower()

    for keywords, subcategory in SMART_RULES[category]:
        for keyword in keywords:
            if keyword.lower() in filename_lower:
                return subcategory

    return None


def get_date_folder(file_path: Path) -> str:
    """è·å–æ–‡ä»¶çš„æ—¥æœŸæ–‡ä»¶å¤¹åï¼ˆå¦‚ 2026-01ï¼‰"""
    try:
        mtime = file_path.stat().st_mtime
        dt = datetime.fromtimestamp(mtime)
        return dt.strftime("%Y-%m")
    except:
        return datetime.now().strftime("%Y-%m")


def should_skip(filename: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥æ–‡ä»¶"""
    if filename in SKIP_FILES:
        return True
    if filename.startswith("."):
        return True
    for pattern in SKIP_PATTERNS:
        if pattern in filename:
            return True
    return False


def get_unique_path(dest_path: Path) -> Path:
    """å¤„ç†é‡åæ–‡ä»¶ï¼Œè¿”å›å”¯ä¸€è·¯å¾„"""
    if not dest_path.exists():
        return dest_path

    base = dest_path.stem
    ext = dest_path.suffix
    parent = dest_path.parent
    counter = 1

    while True:
        new_name = f"{base}_{counter}{ext}"
        new_path = parent / new_name
        if not new_path.exists():
            return new_path
        counter += 1


def format_size(size: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024:
            return f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"


# ============ å†å²è®°å½•ç®¡ç† ============

def load_history() -> List[Dict]:
    """åŠ è½½ç§»åŠ¨å†å²"""
    if not HISTORY_FILE.exists():
        return []
    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return []


def save_history(history: List[Dict]):
    """ä¿å­˜ç§»åŠ¨å†å²"""
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def record_move(source: Path, dest: Path):
    """è®°å½•ä¸€æ¬¡ç§»åŠ¨æ“ä½œ"""
    history = load_history()

    # è·å–æœ€æ–°çš„æ‰¹æ¬¡ID
    batch_id = history[-1]["batch_id"] if history and "batch_id" in history[-1] else 0
    current_batch = history[-1] if history and history[-1].get("batch_id") == batch_id else None

    if current_batch and (datetime.now() - datetime.fromisoformat(current_batch["timestamp"])).seconds < 60:
        # åŒä¸€æ‰¹æ¬¡ï¼ˆ60ç§’å†…ï¼‰
        current_batch["moves"].append({
            "source": str(source),
            "dest": str(dest)
        })
    else:
        # æ–°æ‰¹æ¬¡
        history.append({
            "batch_id": batch_id + 1,
            "timestamp": datetime.now().isoformat(),
            "moves": [{
                "source": str(source),
                "dest": str(dest)
            }]
        })

    save_history(history)


def start_new_batch():
    """å¼€å§‹æ–°çš„æ“ä½œæ‰¹æ¬¡"""
    history = load_history()
    batch_id = history[-1]["batch_id"] + 1 if history else 1
    history.append({
        "batch_id": batch_id,
        "timestamp": datetime.now().isoformat(),
        "moves": []
    })
    save_history(history)
    return batch_id


def add_to_batch(source: Path, dest: Path):
    """æ·»åŠ ç§»åŠ¨è®°å½•åˆ°å½“å‰æ‰¹æ¬¡"""
    history = load_history()
    if history:
        history[-1]["moves"].append({
            "source": str(source),
            "dest": str(dest)
        })
        save_history(history)


# ============ ä¸»è¦åŠŸèƒ½ ============

def calculate_moves(downloads_path: Path, recursive: bool = True) -> Tuple[Dict, List]:
    """è®¡ç®—éœ€è¦ç§»åŠ¨çš„æ–‡ä»¶

    Args:
        downloads_path: ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„
        recursive: æ˜¯å¦é€’å½’æ•´ç†å­æ–‡ä»¶å¤¹
    """
    stats = defaultdict(list)
    skipped = []

    # è·å–æ‰€æœ‰åˆ†ç±»æ–‡ä»¶å¤¹åç§°ï¼ˆé¿å…é‡å¤æ•´ç†å·²åˆ†ç±»çš„æ–‡ä»¶ï¼‰
    category_names = set(CATEGORIES.keys()) | {"å…¶ä»–"}

    def process_file(file_path: Path, base_path: Path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        filename = file_path.name

        if should_skip(filename):
            skipped.append(filename)
            return

        # è·å–åŸºç¡€åˆ†ç±»
        category = get_category(filename)

        # æ™ºèƒ½å­åˆ†ç±»
        subcategory = get_smart_subcategory(filename, category)

        # æ—¥æœŸæ–‡ä»¶å¤¹
        date_folder = get_date_folder(file_path) if ARCHIVE_BY_DATE else None

        # æ„å»ºç›®æ ‡è·¯å¾„
        if subcategory and date_folder:
            dest_folder = base_path / category / subcategory / date_folder
        elif subcategory:
            dest_folder = base_path / category / subcategory
        elif date_folder:
            dest_folder = base_path / category / date_folder
        else:
            dest_folder = base_path / category

        dest_path = dest_folder / filename

        # å¦‚æœæ–‡ä»¶å·²ç»åœ¨æ­£ç¡®ä½ç½®ï¼Œè·³è¿‡
        if file_path.parent == dest_folder:
            return

        dest_path = get_unique_path(dest_path)

        # æ„å»ºåˆ†ç±»é”®ç”¨äºæ˜¾ç¤º
        if subcategory:
            display_category = f"{category}/{subcategory}"
        else:
            display_category = category

        stats[display_category].append({
            "source": file_path,
            "dest": dest_path,
            "size": file_path.stat().st_size,
            "date_folder": date_folder
        })

    def scan_directory(dir_path: Path, base_path: Path, depth: int = 0):
        """é€’å½’æ‰«æç›®å½•"""
        for item in dir_path.iterdir():
            if item.is_file():
                process_file(item, base_path)
            elif item.is_dir() and recursive:
                # è·³è¿‡éšè—æ–‡ä»¶å¤¹å’Œ.appåŒ…
                if item.name.startswith(".") or item.name.endswith(".app"):
                    continue
                # é€’å½’æ‰«æå­æ–‡ä»¶å¤¹ï¼ˆä½†éƒ½å½’ç±»åˆ°é¡¶å±‚åˆ†ç±»æ–‡ä»¶å¤¹ï¼‰
                scan_directory(item, base_path, depth + 1)

    scan_directory(downloads_path, downloads_path)
    return stats, skipped


def print_preview(stats: Dict, skipped: List, dry_run: bool = True):
    """æ‰“å°é¢„è§ˆä¿¡æ¯"""
    print("\n" + "="*60)
    print(f"{'ğŸ“‹ é¢„è§ˆæ¨¡å¼' if dry_run else 'ğŸš€ æ‰§è¡Œæ¨¡å¼'}")
    if ARCHIVE_BY_DATE:
        print(f"ğŸ“… æŒ‰æ—¥æœŸå½’æ¡£å·²å¯ç”¨")
    print("="*60)

    total_files = 0
    total_size = 0

    for category, files in sorted(stats.items()):
        count = len(files)
        size = sum(f["size"] for f in files)
        total_files += count
        total_size += size

        print(f"\nğŸ“ {category}/ ({count}ä¸ªæ–‡ä»¶, {format_size(size)})")

        # æŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
        if ARCHIVE_BY_DATE:
            by_date = defaultdict(list)
            for f in files:
                by_date[f["date_folder"]].append(f)

            for date_folder in sorted(by_date.keys(), reverse=True):
                date_files = by_date[date_folder]
                print(f"   ğŸ“† {date_folder}/ ({len(date_files)}ä¸ª)")
                for f in date_files[:3]:
                    print(f"      â””â”€ {f['source'].name}")
                if len(date_files) > 3:
                    print(f"      â””â”€ ... è¿˜æœ‰{len(date_files)-3}ä¸ªæ–‡ä»¶")
        else:
            for f in files[:5]:
                print(f"   â””â”€ {f['source'].name}")
            if len(files) > 5:
                print(f"   â””â”€ ... è¿˜æœ‰{len(files)-5}ä¸ªæ–‡ä»¶")

    print(f"\n" + "-"*60)
    print(f"æ€»è®¡: {total_files}ä¸ªæ–‡ä»¶, {format_size(total_size)}")

    if skipped:
        print(f"è·³è¿‡: {len(skipped)}ä¸ªæ–‡ä»¶ (éšè—æ–‡ä»¶/æ­£åœ¨ä¸‹è½½)")


def organize_downloads(downloads_path: Path, dry_run: bool = True):
    """æ•´ç†ä¸‹è½½æ–‡ä»¶å¤¹"""
    if not downloads_path.exists():
        print(f"é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨ {downloads_path}")
        return

    stats, skipped = calculate_moves(downloads_path)
    print_preview(stats, skipped, dry_run)

    if dry_run:
        print(f"\nğŸ’¡ è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œæœªåšä»»ä½•æ›´æ”¹")
        print(f"   æ‰§è¡Œæ•´ç†è¯·è¿è¡Œ: python {Path(__file__).name} --execute")
        print(f"   å¯åŠ¨ç›‘æ§æ¨¡å¼: python {Path(__file__).name} --watch")
        return

    # å¼€å§‹æ–°æ‰¹æ¬¡
    batch_id = start_new_batch()
    print(f"\næ­£åœ¨æ•´ç†æ–‡ä»¶... (æ‰¹æ¬¡ #{batch_id})")

    moved_count = 0
    total_files = sum(len(files) for files in stats.values())

    for category, files in stats.items():
        for f in files:
            try:
                f["dest"].parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(f["source"]), str(f["dest"]))
                add_to_batch(f["source"], f["dest"])
                moved_count += 1
            except Exception as e:
                print(f"   âŒ ç§»åŠ¨å¤±è´¥: {f['source'].name} - {e}")

    print(f"\nâœ… å®Œæˆï¼æˆåŠŸç§»åŠ¨ {moved_count}/{total_files} ä¸ªæ–‡ä»¶")
    print(f"   å¦‚éœ€æ’¤é”€ï¼Œè¿è¡Œ: python {Path(__file__).name} --undo")


def undo_last_batch():
    """æ’¤é”€æœ€åä¸€æ‰¹ç§»åŠ¨æ“ä½œ"""
    history = load_history()

    if not history:
        print("æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")
        return

    # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆæ‰¹æ¬¡
    last_batch = None
    for batch in reversed(history):
        if batch["moves"]:
            last_batch = batch
            break

    if not last_batch:
        print("æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")
        return

    print(f"\næ’¤é”€æ‰¹æ¬¡ #{last_batch['batch_id']} ({last_batch['timestamp']})")
    print(f"å…± {len(last_batch['moves'])} ä¸ªæ–‡ä»¶")
    print("-" * 40)

    restored = 0
    for move in last_batch["moves"]:
        source = Path(move["source"])
        dest = Path(move["dest"])

        if dest.exists():
            try:
                # ç¡®ä¿æºç›®å½•å­˜åœ¨
                source.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(dest), str(source))
                print(f"   âœ… è¿˜åŸ: {source.name}")
                restored += 1
            except Exception as e:
                print(f"   âŒ è¿˜åŸå¤±è´¥: {dest.name} - {e}")
        else:
            print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {dest}")

    # ä»å†å²ä¸­ç§»é™¤è¯¥æ‰¹æ¬¡
    history = [b for b in history if b["batch_id"] != last_batch["batch_id"]]
    save_history(history)

    print(f"\nâœ… å·²è¿˜åŸ {restored}/{len(last_batch['moves'])} ä¸ªæ–‡ä»¶")

    # æ¸…ç†ç©ºæ–‡ä»¶å¤¹
    cleanup_empty_folders(DOWNLOADS_PATH)


def cleanup_empty_folders(path: Path):
    """æ¸…ç†ç©ºæ–‡ä»¶å¤¹"""
    for folder in path.iterdir():
        if folder.is_dir() and folder.name not in SKIP_FILES:
            cleanup_empty_folders(folder)
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºï¼ˆå¿½ç•¥.DS_Storeï¼‰
                contents = [f for f in folder.iterdir() if f.name != ".DS_Store"]
                if not contents:
                    # åˆ é™¤.DS_Storeå’Œæ–‡ä»¶å¤¹
                    for f in folder.iterdir():
                        f.unlink()
                    folder.rmdir()
            except:
                pass


def show_history():
    """æ˜¾ç¤ºç§»åŠ¨å†å²"""
    history = load_history()

    if not history:
        print("æ²¡æœ‰æ“ä½œå†å²")
        return

    print("\nğŸ“œ æ“ä½œå†å²")
    print("=" * 60)

    for batch in reversed(history[-10:]):  # åªæ˜¾ç¤ºæœ€è¿‘10æ‰¹
        timestamp = datetime.fromisoformat(batch["timestamp"]).strftime("%Y-%m-%d %H:%M:%S")
        count = len(batch["moves"])
        print(f"\næ‰¹æ¬¡ #{batch['batch_id']} | {timestamp} | {count}ä¸ªæ–‡ä»¶")

        for move in batch["moves"][:3]:
            source_name = Path(move["source"]).name
            dest_folder = Path(move["dest"]).parent.relative_to(DOWNLOADS_PATH)
            print(f"   {source_name} â†’ {dest_folder}/")

        if count > 3:
            print(f"   ... è¿˜æœ‰{count-3}ä¸ªæ–‡ä»¶")


# ============ ç›‘æ§æ¨¡å¼ ============

class DownloadHandler(FileSystemEventHandler):
    """æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨"""

    def __init__(self, downloads_path: Path):
        self.downloads_path = downloads_path
        self.pending_files = {}  # ç­‰å¾…å¤„ç†çš„æ–‡ä»¶
        self.process_delay = 2  # ç­‰å¾…æ–‡ä»¶ä¸‹è½½å®Œæˆçš„å»¶è¿Ÿï¼ˆç§’ï¼‰

    def on_created(self, event):
        if event.is_directory:
            return
        self._schedule_process(Path(event.src_path))

    def on_moved(self, event):
        if event.is_directory:
            return
        # æ–‡ä»¶ç§»åŠ¨åˆ°ä¸‹è½½æ–‡ä»¶å¤¹ï¼ˆå¦‚Chromeä¸‹è½½å®Œæˆï¼‰
        dest_path = Path(event.dest_path)
        if dest_path.parent == self.downloads_path:
            self._schedule_process(dest_path)

    def _schedule_process(self, file_path: Path):
        """å»¶è¿Ÿå¤„ç†æ–‡ä»¶ï¼ˆç­‰å¾…ä¸‹è½½å®Œæˆï¼‰"""
        if file_path.parent != self.downloads_path:
            return

        filename = file_path.name

        if should_skip(filename):
            return

        # è®°å½•æ–‡ä»¶ï¼Œç¨åå¤„ç†
        self.pending_files[str(file_path)] = time.time()

    def process_pending(self):
        """å¤„ç†ç­‰å¾…ä¸­çš„æ–‡ä»¶"""
        now = time.time()
        to_remove = []

        for file_path_str, timestamp in list(self.pending_files.items()):
            if now - timestamp < self.process_delay:
                continue

            file_path = Path(file_path_str)
            to_remove.append(file_path_str)

            if not file_path.exists():
                continue

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿˜åœ¨è¢«å†™å…¥
            try:
                size1 = file_path.stat().st_size
                time.sleep(0.5)
                size2 = file_path.stat().st_size
                if size1 != size2:
                    # æ–‡ä»¶è¿˜åœ¨ä¸‹è½½ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
                    self.pending_files[file_path_str] = now
                    to_remove.remove(file_path_str)
                    continue
            except:
                continue

            # å¤„ç†æ–‡ä»¶
            self._process_file(file_path)

        for path in to_remove:
            self.pending_files.pop(path, None)

    def _process_file(self, file_path: Path):
        """æ•´ç†å•ä¸ªæ–‡ä»¶"""
        filename = file_path.name

        # è·å–åˆ†ç±»
        category = get_category(filename)
        subcategory = get_smart_subcategory(filename, category)
        date_folder = get_date_folder(file_path) if ARCHIVE_BY_DATE else None

        # æ„å»ºç›®æ ‡è·¯å¾„
        if subcategory and date_folder:
            dest_folder = self.downloads_path / category / subcategory / date_folder
        elif subcategory:
            dest_folder = self.downloads_path / category / subcategory
        elif date_folder:
            dest_folder = self.downloads_path / category / date_folder
        else:
            dest_folder = self.downloads_path / category

        dest_path = dest_folder / filename
        dest_path = get_unique_path(dest_path)

        try:
            dest_folder.mkdir(parents=True, exist_ok=True)
            shutil.move(str(file_path), str(dest_path))
            record_move(file_path, dest_path)

            # æ˜¾ç¤ºåˆ†ç±»ä¿¡æ¯
            display_category = f"{category}/{subcategory}" if subcategory else category
            print(f"   âœ… {filename} â†’ {display_category}/{date_folder or ''}")
        except Exception as e:
            print(f"   âŒ ç§»åŠ¨å¤±è´¥: {filename} - {e}")


def watch_downloads(downloads_path: Path):
    """ç›‘æ§æ¨¡å¼"""
    if not WATCHDOG_AVAILABLE:
        print("âŒ ç›‘æ§æ¨¡å¼éœ€è¦å®‰è£… watchdog åº“")
        print("   è¿è¡Œ: pip install watchdog")
        return

    print("\n" + "="*60)
    print("ğŸ‘€ ç›‘æ§æ¨¡å¼å·²å¯åŠ¨")
    print("="*60)
    print(f"ç›‘æ§è·¯å¾„: {downloads_path}")
    print(f"æŒ‰æ—¥æœŸå½’æ¡£: {'æ˜¯' if ARCHIVE_BY_DATE else 'å¦'}")
    print(f"æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
    print("-"*60 + "\n")

    handler = DownloadHandler(downloads_path)
    observer = Observer()
    observer.schedule(handler, str(downloads_path), recursive=False)
    observer.start()

    try:
        while True:
            time.sleep(1)
            handler.process_pending()
    except KeyboardInterrupt:
        print("\n\nåœæ­¢ç›‘æ§...")
        observer.stop()

    observer.join()
    print("âœ… ç›‘æ§å·²åœæ­¢")


# ============ ä¸»å…¥å£ ============

def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½æ–‡ä»¶å¤¹æ™ºèƒ½æ•´ç†å·¥å…· v2.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python organize_downloads.py           # é¢„è§ˆæ¨¡å¼
  python organize_downloads.py -e        # æ‰§è¡Œæ•´ç†
  python organize_downloads.py -w        # ç›‘æ§æ¨¡å¼
  python organize_downloads.py --undo    # æ’¤é”€ä¸Šæ¬¡æ“ä½œ
  python organize_downloads.py --no-date # ä¸æŒ‰æ—¥æœŸå½’æ¡£
        """
    )
    parser.add_argument(
        "--execute", "-e",
        action="store_true",
        help="æ‰§è¡Œæ¨¡å¼ï¼Œå®é™…ç§»åŠ¨æ–‡ä»¶"
    )
    parser.add_argument(
        "--watch", "-w",
        action="store_true",
        help="ç›‘æ§æ¨¡å¼ï¼Œå®æ—¶æ•´ç†æ–°ä¸‹è½½çš„æ–‡ä»¶"
    )
    parser.add_argument(
        "--undo", "-u",
        action="store_true",
        help="æ’¤é”€ä¸Šä¸€æ‰¹ç§»åŠ¨æ“ä½œ"
    )
    parser.add_argument(
        "--history",
        action="store_true",
        help="æ˜¾ç¤ºæ“ä½œå†å²"
    )
    parser.add_argument(
        "--no-date",
        action="store_true",
        help="ä¸æŒ‰æ—¥æœŸå½’æ¡£"
    )
    parser.add_argument(
        "--path", "-p",
        default=str(DOWNLOADS_PATH),
        help=f"ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆé»˜è®¤ {DOWNLOADS_PATH}ï¼‰"
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥æœŸå½’æ¡£é€‰ï¿½ï¿½
    global ARCHIVE_BY_DATE
    if args.no_date:
        ARCHIVE_BY_DATE = False

    downloads_path = Path(args.path).expanduser()

    if args.undo:
        undo_last_batch()
    elif args.history:
        show_history()
    elif args.watch:
        watch_downloads(downloads_path)
    else:
        dry_run = not args.execute
        organize_downloads(downloads_path, dry_run=dry_run)


if __name__ == "__main__":
    main()
